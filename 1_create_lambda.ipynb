{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import boto3\n",
    "import logging\n",
    "from globals import *\n",
    "from pathlib import Path\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# global constants\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "CONFIG_FILE: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mconfig.yml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "MODEL_ID_TOPROMPT_ID_MAPPING_FILE: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33m.model_id_to_prompt_id_mapping.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "LAMBDA_DIR: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mlambda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "CONFIG_FILE: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mconfig.yml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "CODE_GEN_LAMBDA: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33mcode-gen\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "LAMBDA_ARN_FILE: \u001b[36mstr\u001b[39;49;00m = \u001b[33m\"\u001b[39;49;00m\u001b[33m.lambda_arn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize globals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-19 03:03:49,632] p21089 {3811199622.py:2} INFO - config=\n",
      "{\n",
      "  \"general\": {\n",
      "    \"app_name\": \"code-gen-agent\",\n",
      "    \"description\": \"Amazon Bedrock Agent for generating code for the USACO benchmark\",\n",
      "    \"role_name\": \"CodeGenLambdaRole\",\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"model_id\": \"amazon.nova-micro-v1:0\",\n",
      "    \"agent_instructions\": \"Generate Python code for the USACO problems. You have access to a tool for generating the code.\\n\",\n",
      "    \"ttl\": 1800\n",
      "  },\n",
      "  \"action_group\": {\n",
      "    \"name\": \"Generate_Python_code\",\n",
      "    \"description\": \"Generates Python code by using foundation models\"\n",
      "  },\n",
      "  \"prompt_info\": {\n",
      "    \"name\": \"USACO_{model_id}\",\n",
      "    \"description\": \"Generate code for the USACO benchmark\"\n",
      "  },\n",
      "  \"prompt_templates\": {\n",
      "    \"nova\": {\n",
      "      \"models\": [\n",
      "        \"amazon.nova-pro-v1:0\",\n",
      "        \"amazon.nova-lite-v1:0\",\n",
      "        \"amazon.nova-micro-v1:0\"\n",
      "      ],\n",
      "      \"text\": \"Please reply with a Python 3 solution to the below problem. Read the general instructions below that are applicable to every task,\\n\\n{{question}}\\n\\nImportant instructions to follow:\\n\\n1. Ensure that your code is wrapped in '```python' and '```' Markdown delimiters.\\n2. Provide exactly one block of code containing the entire solution.\\n3. The code should include a main function and an `if __name__ == \\\"__main__\\\"` block as the entry point.\\n4. Begin by reasoning through the problem and conceptualizing a solution. Then, write pseudocode, and finally output the Python code with your solution steps in comments.\\n5. Carefully examine the SAMPLE INPUT: and SAMPLE OUTPUT: sections provided as part of the problem and follow the format exactly as specified there.\\n6. If there are empty lines separating multiple sample inputs in the SAMPLE INPUT: section provided in the problem, handle them appropriately.\\n7. Do not use any outside libraries.\\n\"\n",
      "    },\n",
      "    \"claude\": {\n",
      "      \"models\": [\n",
      "        \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
      "        \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
      "      ],\n",
      "      \"text\": \"Please reply with a Python 3 solution to the below problem. Read the general instructions below\\nthat are applicable to every task,\\n\\n<instructions>\\n1. Make sure to wrap your code in '```python' and '```' Markdown delimiters.\\n2. Include exactly one block of code with the entire solution.\\n3. The code should always have main function and an if __name__ == \\\"__main__\\\" block as the entrypoint.\\n4. Reason through the problem and conceptualize a solution first, then write pseudocode, and finally output the Python with your solution steps in comments.\\n5. Carefully examine the SAMPLE INPUT: and SAMPLE OUTPUT: sections provided as part of the problem and follow the format exactly as specified there.\\n6. There might be empty lines separating multiple sample inputs, check the SAMPLE INPUT: section provided in the problem, if there are empty lines separating different inputs then handle them appropriately.\\n7. No outside libraries are allowed.\\n</instructions> \\n\\n<problem>>\\n{{question}}\\n</problem>\\n\"\n",
      "    }\n",
      "  },\n",
      "  \"inference_parameters\": {\n",
      "    \"temperature\": 0.7,\n",
      "    \"max_tokens\": 2000\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = yaml.safe_load(Path(CONFIG_FILE).read_text())\n",
    "logger.info(f\"config=\\n{json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export REGION=us-east-1\n",
      "region=us-east-1, image=latest, account=015469603702, image=latest, repo=code_gen#, base image=\n",
      "\"code_gen\"\n",
      "code_gen already exists, no need to create it\n",
      "user=ubuntu, building the container image 015469603702.dkr.ecr.us-east-1.amazonaws.com/code_gen:latest\n",
      "DEPRECATED: The legacy builder is deprecated and will be removed in a future release.\n",
      "            Install the buildx component to build images with BuildKit:\n",
      "            https://docs.docker.com/go/buildx/\n",
      "\n",
      "Sending build context to Docker daemon   21.5kB\n",
      "Step 1/8 : FROM amazon/aws-lambda-python:3.11\n",
      " ---> c14937f0dcb9\n",
      "Step 2/8 : COPY requirements.txt ${LAMBDA_TASK_ROOT}\n",
      " ---> Using cache\n",
      " ---> bed1b585a98d\n",
      "Step 3/8 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 74ca82e57309\n",
      "Step 4/8 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 4d63a7329e6a\n",
      "Step 5/8 : RUN pip install -U boto3 botocore\n",
      " ---> Using cache\n",
      " ---> d4a4acc5348a\n",
      "Step 6/8 : COPY index.py ${LAMBDA_TASK_ROOT}\n",
      " ---> cb2ff281e94e\n",
      "Step 7/8 : COPY tools.py ${LAMBDA_TASK_ROOT}\n",
      " ---> 0a1248182ecf\n",
      "Step 8/8 : CMD [ \"index.handler\" ]\n",
      " ---> Running in 7df33cf78827\n",
      " ---> Removed intermediate container 7df33cf78827\n",
      " ---> 119097442559\n",
      "Successfully built 119097442559\n",
      "Successfully tagged latest:latest\n",
      "Successfully tagged 015469603702.dkr.ecr.us-east-1.amazonaws.com/code_gen:latest\n",
      "015469603702.dkr.ecr.us-east-1.amazonaws.com/code_gen:latest created successfully\n",
      "logging into ECR to push image we just built\n",
      "WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "pushing 015469603702.dkr.ecr.us-east-1.amazonaws.com/code_gen:latest to ECR\n",
      "The push refers to repository [015469603702.dkr.ecr.us-east-1.amazonaws.com/code_gen]\n",
      "\n",
      "\u001b[1Bde2123c1: Preparing \n",
      "\u001b[1Bef3e9056: Preparing \n",
      "\u001b[1Bfe54b2f7: Preparing \n",
      "\u001b[1B09461320: Preparing \n",
      "\u001b[1B52767400: Preparing \n",
      "\u001b[1B1c8e3edc: Preparing \n",
      "\u001b[1B944ab421: Preparing \n",
      "\u001b[1Bb319fa5a: Preparing \n",
      "\u001b[1Bb0f618e4: Preparing \n",
      "\u001b[1B6697921a: Preparing \n",
      "\u001b[1Ba02a2541: Preparing \n",
      "\u001b[11Bf3e9056: Pushed lready exists 2kB[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2Klatest: digest: sha256:ae4e9b8ddaf9ce9b4bf4259125fed6ac41d348db737129450409f27b15044c95 size: 2833\n",
      "015469603702.dkr.ecr.us-east-1.amazonaws.com/code_gen:latest pushed successfully\n",
      "all done\n",
      "/home/ubuntu/repos/bedrock-code-agent\n"
     ]
    }
   ],
   "source": [
    "!source .venv/bin/activate &&  cd {LAMBDA_DIR} && ./build_and_push.sh code_gen && cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-19 03:03:53,718] p21089 {2528287115.py:55} INFO - code-gen lambda does exist, updating it with latest code\n",
      "[2025-01-19 03:03:54,551] p21089 {2528287115.py:61} INFO - {'ResponseMetadata': {'RequestId': 'a6cd5f16-ceb8-48e0-aa5c-3dc30431e1cf', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 19 Jan 2025 03:03:54 GMT', 'content-type': 'application/json', 'content-length': '1532', 'connection': 'keep-alive', 'x-amzn-requestid': 'a6cd5f16-ceb8-48e0-aa5c-3dc30431e1cf'}, 'RetryAttempts': 0}, 'FunctionName': 'code-gen', 'FunctionArn': 'arn:aws:lambda:us-east-1:015469603702:function:code-gen:16', 'Role': 'arn:aws:iam::015469603702:role/CodeGenLambdaRole', 'CodeSize': 0, 'Description': 'Generate code using Amazon Bedrock', 'Timeout': 90, 'MemorySize': 10240, 'LastModified': '2025-01-19T03:03:54.000+0000', 'CodeSha256': 'ae4e9b8ddaf9ce9b4bf4259125fed6ac41d348db737129450409f27b15044c95', 'Version': '16', 'Environment': {'Variables': {'MODEL_ID_TO_PROMPT_ID_MAPPING': '{\\n  \"amazon.nova-pro-v1:0\": \"FPPQT96U8Y\",\\n  \"amazon.nova-lite-v1:0\": \"RJG7KU4HDN\",\\n  \"amazon.nova-micro-v1:0\": \"P2CS53D4NC\",\\n  \"us.anthropic.claude-3-5-haiku-20241022-v1:0\": \"6FM16J82V8\",\\n  \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\": \"4XQSDFVR7I\"\\n}'}}, 'TracingConfig': {'Mode': 'Active'}, 'RevisionId': 'bb2939e0-c607-4db4-bdca-e49cabd58686', 'State': 'Pending', 'StateReason': 'The function is being created.', 'StateReasonCode': 'Creating', 'PackageType': 'Image', 'Architectures': ['x86_64'], 'EphemeralStorage': {'Size': 512}, 'SnapStart': {'ApplyOn': 'None', 'OptimizationStatus': 'Off'}, 'LoggingConfig': {'LogFormat': 'Text', 'LogGroup': '/aws/lambda/code-gen'}}\n"
     ]
    }
   ],
   "source": [
    "# create a lambda function using this image\n",
    "def function_exists(function_name: str, region_name: str) -> bool:\n",
    "        \"\"\"Check if Lambda function exists.\"\"\"\n",
    "        try:\n",
    "            client = boto3.client(\"lambda\", region_name=region_name)\n",
    "            client.get_function(FunctionName=function_name)\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "                return False\n",
    "            raise\n",
    "\n",
    "IMAGE_URI_FILE: str = os.path.join(LAMBDA_DIR, \"image\")\n",
    "image = Path(IMAGE_URI_FILE).read_text().strip()\n",
    "role_name: str = config['general']['role_name']\n",
    "account: str = boto3.client('sts').get_caller_identity()['Account']\n",
    "role = f\"arn:aws:iam::{account}:role/{role_name}\"\n",
    "memory = 1024*10\n",
    "timeout: int = 90\n",
    "region_name: str = config['general']['region']\n",
    "lambda_name: str = CODE_GEN_LAMBDA\n",
    "\n",
    "client = boto3.client(\"lambda\", region_name=region_name)\n",
    "\n",
    "if function_exists(lambda_name, region_name) is not True:\n",
    "    logger.info(f\"{lambda_name} lambda does not exist, creating it now\")\n",
    "    logger.info(f\"building lambda function with lambda_name={lambda_name}, image={image}, region_name={region_name}, role={role}, memory={memory}, timeout={timeout}\")\n",
    "\n",
    "    response = client.create_function(\n",
    "        PackageType='Image',  # Specify we're using a container image\n",
    "        Code={\n",
    "            'ImageUri': image\n",
    "        },\n",
    "        Description='Generate code using Amazon Bedrock',\n",
    "        Environment={\n",
    "            'Variables': {\n",
    "                'MODEL_ID_TO_PROMPT_ID_MAPPING': Path(MODEL_ID_TOPROMPT_ID_MAPPING_FILE).read_text()\n",
    "            },\n",
    "        },\n",
    "        FunctionName=lambda_name,\n",
    "        MemorySize=memory,\n",
    "        Publish=True,\n",
    "        Role=role,\n",
    "        Tags={\n",
    "            'TEAM': 'GenAIDevs',\n",
    "        },\n",
    "        Timeout=timeout,\n",
    "        TracingConfig={\n",
    "            'Mode': 'Active',\n",
    "        },\n",
    "        Architectures=['x86_64']  # or ['arm64'] for ARM-based\n",
    "    )\n",
    "    logger.info(response)\n",
    "else:\n",
    "     logger.info(f\"{lambda_name} lambda does exist, updating it with latest code\")\n",
    "     response = client.update_function_code(\n",
    "                    FunctionName=lambda_name,\n",
    "                    ImageUri=image,\n",
    "                    Publish=True,\n",
    "                )\n",
    "     logger.info(response)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-19 03:03:54,559] p21089 {4097021626.py:2} INFO - lambda creation or update done, arn=arn:aws:lambda:us-east-1:015469603702:function:code-gen:16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_arn: str = response['FunctionArn']\n",
    "logger.info(f\"lambda creation or update done, arn={lambda_arn}\")\n",
    "Path(LAMBDA_ARN_FILE).write_text(lambda_arn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
